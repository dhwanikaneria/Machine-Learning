In [1]:

Best Model:

import pandas as pd
import numpy as np
df=pd.read_csv("http://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data",names=['cap-shape','cap-surface','cap-color','bruises','odor','gill-spacing ',' gill-attachment',' gill-size ','gill-color','stalk-shape','stalk-root','stalk-surface-above-ring','stalk-surface-below-ring','stalk-color-above-ring  ','stalk-color-below-ring ','veil-type','veil-color','ring-number','ring-type','spore-print-color','population ','habitat','Class'],index_col=False)

#Filling missing values with mean value
df.fillna(df.mean(), inplace=True)

#preprocessing catorigal data
from sklearn import preprocessing
X = df.apply(preprocessing.LabelEncoder().fit_transform).iloc[:,:-1]
y = df.apply(preprocessing.LabelEncoder().fit_transform).iloc[:,-1]
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y)

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()

#fit into scaler
scaler.fit(X_train)

#transform with scaler
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

from sklearn.neural_network import MLPClassifier
from sklearn.neural_network import MLPClassifier

#create model
mlp = MLPClassifier(activation='relu',solver='sgd',hidden_layer_sizes=(20,20,20), max_iter=2000, learning_rate_init=0.001, alpha=1e-5, random_state=0)
mlp.fit(X_train,y_train)


from sklearn.metrics import classification_report,confusion_matrix

#Prediction for train data
print('Prediction for train data')
predictions = mlp.predict(X_train)
print(confusion_matrix(y_train,predictions))
print(classification_report(y_train,predictions))

#prediction for test data
predictions = mlp.predict(X_test)
print('prediction for test data')
print(confusion_matrix(y_test,predictions))
print(classification_report(y_test,predictions))


Output:

Out [1]:
Index([u'cap-shape', u'cap-surface', u'cap-color', u'bruises', u'odor',
       u'gill-spacing ', u' gill-attachment', u' gill-size ', u'gill-color',
       u'stalk-shape', u'stalk-root', u'stalk-surface-above-ring',
       u'stalk-surface-below-ring', u'stalk-color-above-ring  ',
       u'stalk-color-below-ring ', u'veil-type', u'veil-color', u'ring-number',
       u'ring-type', u'spore-print-color', u'population ', u'habitat',
       u'Class'],
      dtype='object')
       cap-shape cap-surface cap-color bruises  odor gill-spacing   \
count       8124        8124      8124    8124  8124          8124   
unique         2           6         4      10     2             9   
top            e           x         y       n     f             n   
freq        4208        3656      3244    2284  4748          3528   

        gill-attachment  gill-size  gill-color stalk-shape  ...   \
count              8124        8124       8124        8124  ...    
unique                2           2          2          12  ...    
top                   f           c          b           b  ...    
freq               7914        6812       5612        1728  ...    

       stalk-color-above-ring   stalk-color-below-ring  veil-type veil-color  \
count                      8124                    8124      8124       8124   
unique                        4                       9         9          1   
top                           s                       w         w          p   
freq                       4936                    4464      4384       8124   

       ring-number ring-type spore-print-color population  habitat Class  
count         8124      8124              8124        8124    8124  8124  
unique           4         3                 5           9       6     7  
top              w         o                 p           w       v     d  
freq          7924      7488              3968        2388    4040  3148  

[4 rows x 23 columns]
  cap-shape cap-surface cap-color bruises odor gill-spacing   gill-attachment  \
0         p           x         s       n    t             p                f   
1         e           x         s       y    t             a                f   
2         e           b         s       w    t             l                f   
3         p           x         y       w    t             p                f   
4         e           x         s       g    f             n                f   

   gill-size  gill-color stalk-shape  ...  stalk-color-above-ring    \
0           c          n           k  ...                         s   
1           c          b           k  ...                         s   
2           c          b           n  ...                         s   
3           c          n           n  ...                         s   
4           w          b           k  ...                         s   

  stalk-color-below-ring  veil-type veil-color ring-number ring-type  \
0                       w         w          p           w         o   
1                       w         w          p           w         o   
2                       w         w          p           w         o   
3                       w         w          p           w         o   
4                       w         w          p           w         o   

  spore-print-color population  habitat Class  
0                 p           k       s     u  
1                 p           n       n     g  
2                 p           n       n     m  
3                 p           k       s     u  
4                 e           n       a     g  

[5 rows x 23 columns]

Prediction for train data
[[1768  141  129    0  304    0    0]
 [  69 1208    0  117  157   88    0]
 [ 109    0  321    0  187    0    0]
 [   0  116    0  116    0    0    0]
 [ 183  165  119    2  389    0    0]
 [   0  106    0    0    0  162    0]
 [   0    0    0    0    0    0  137]]
             precision    recall  f1-score   support

          0       0.83      0.75      0.79      2342
          1       0.70      0.74      0.72      1639
          2       0.56      0.52      0.54       617
          3       0.49      0.50      0.50       232
          4       0.38      0.45      0.41       858
          5       0.65      0.60      0.63       268
          6       1.00      1.00      1.00       137

avg / total       0.69      0.67      0.68      6093

prediction for test data
[[593  41  50   0 122   0   0]
 [ 22 362   0  29  61  35   0]
 [ 29   0 114   0  72   0   0]
 [  0  30   0  30   0   0   0]
 [ 46  54  60   2 124   0   0]
 [  0  43   0   0   0  57   0]
 [  0   0   0   0   0   0  55]]
             precision    recall  f1-score   support

          0       0.86      0.74      0.79       806
          1       0.68      0.71      0.70       509
          2       0.51      0.53      0.52       215
          3       0.49      0.50      0.50        60
          4       0.33      0.43      0.37       286
          5       0.62      0.57      0.59       100
          6       1.00      1.00      1.00        55

avg / total       0.68      0.66      0.67      2031


different variations:
Model 1:
In [3]:
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report,confusion_matrix

mlp= MLPClassifier(hidden_layer_sizes=(30,30,30),max_iter=2000)
mlp.fit(X_train,y_train)

from sklearn.metrics import classification_report,confusion_matrix
print('Training predictions')
#Prediction for training data
print('Training predictions')
predictions = mlp.predict(X_train)
print(confusion_matrix(y_train,predictions))
print(classification_report(y_train,predictions))

#Prediction for test data
print('Testing predictions')
predictions = mlp.predict(X_test)
print(confusion_matrix(y_test,predictions))
print(classification_report(y_test,predictions))

Out [3]:
Training predictions
[[2185  269    5    0   59    0    0]
 [  19 1236    0  157   89  206    0]
 [ 444    0  220    0    4    0    0]
 [   0   56    0  188    0    0    0]
 [ 472  293    6    0  137    0    0]
 [   0    2    0    0    0  300    0]
 [   0    0    0    0    0    0  152]]
             precision    recall  f1-score   support

          0       0.70      0.87      0.78      2518
          1       0.67      0.72      0.69      1707
          2       0.95      0.33      0.49       668
          3       0.54      0.77      0.64       244
          4       0.47      0.15      0.23       908
          5       0.59      0.99      0.74       302
          6       1.00      1.00      1.00       152

avg / total       0.68      0.68      0.65      6499

Testing predictions
[[136 110 110   0   0 274   0]
 [ 24 347   0   0   0  70   0]
 [  7  11 139   0   0   7   0]
 [  0  43   0   0   0   5   0]
 [ 26  78 111   0   0  21   0]
 [  0  14   0   0   0  52   0]
 [  1   0  39   0   0   0   0]]
             precision    recall  f1-score   support

          0       0.70      0.22      0.33       630
          1       0.58      0.79      0.66       441
          2       0.35      0.85      0.49       164
          3       0.00      0.00      0.00        48
          4       0.00      0.00      0.00       236
          5       0.12      0.79      0.21        66
          6       0.00      0.00      0.00        40

avg / total       0.47      0.41      0.37      1625


Model 2:
mlp = MLPClassifier(solver='lbfgs', 
                    activation='relu', 
                    alpha=0.0001, 
                    hidden_layer_sizes=(45,35,30), #70, 59
                    learning_rate_init=0.001,
                    max_iter=500,
                    random_state=10)
mlp.fit(X_train,y_train)


Out [3]:
Training predictions
[[2025  108  135    0  250    0    0]
 [ 118 1186    0  168  120  115    0]
 [ 135    0  383    0  150    0    0]
 [   0   44    0  200    0    0    0]
 [ 265  145  130    0  368    0    0]
 [   0   72    0    0    0  230    0]
 [   0    0    0    0    0    0  152]]
             precision    recall  f1-score   support

          0       0.80      0.80      0.80      2518
          1       0.76      0.69      0.73      1707
          2       0.59      0.57      0.58       668
          3       0.54      0.82      0.65       244
          4       0.41      0.41      0.41       908
          5       0.67      0.76      0.71       302
          6       1.00      1.00      1.00       152

avg / total       0.70      0.70      0.70      6499

Testing predictions
[[239  23 108   0   6 254   0]
 [ 24 210   4   6  67 130   0]
 [ 16   0 133   0  11   4   0]
 [  0  35   0   5   0   8   0]
 [ 23  36 108   0  10  59   0]
 [  0   1   0   0   0  65   0]
 [  0   0   8   0  27   0   5]]
             precision    recall  f1-score   support

          0       0.79      0.38      0.51       630
          1       0.69      0.48      0.56       441
          2       0.37      0.81      0.51       164
          3       0.45      0.10      0.17        48
          4       0.08      0.04      0.06       236
          5       0.12      0.98      0.22        66
          6       1.00      0.12      0.22        40

avg / total       0.59      0.41      0.43      1625


Model 3:
mlp = MLPClassifier(solver='lbfgs', 
                    activation='relu', 
                    alpha=0.0001, 
              	    hidden_layer_sizes=(24,24,12,12,12),
                    learning_rate_init=0.001,
                    max_iter=200,
                    random_state=10)
mlp.fit(X_train,y_train)

Out [3]:
Training predictions
[[2074  122  101    0  221    0    0]
 [ 125 1117    0  161  144  160    0]
 [ 225    0  316    0  127    0    0]
 [   0   53    0  191    0    0    0]
 [ 359  139  106    0  304    0    0]
 [   0   46    0    0    0  256    0]
 [   0    0    0    0    0    0  152]]
             precision    recall  f1-score   support

          0       0.75      0.82      0.78      2518
          1       0.76      0.65      0.70      1707
          2       0.60      0.47      0.53       668
          3       0.54      0.78      0.64       244
          4       0.38      0.33      0.36       908
          5       0.62      0.85      0.71       302
          6       1.00      1.00      1.00       152

avg / total       0.68      0.68      0.67      6499

Testing predictions
[[450   2 126   0   0  52   0]
 [ 70 156  40   0   1 174   0]
 [ 20   4 140   0   0   0   0]
 [  3   0   0   0   0  45   0]
 [ 60   2 121   0   0  53   0]
 [  0   0   0   0   0  66   0]
 [  0   0  40   0   0   0   0]]
             precision    recall  f1-score   support

          0       0.75      0.71      0.73       630
          1       0.95      0.35      0.52       441
          2       0.30      0.85      0.44       164
          3       0.00      0.00      0.00        48
          4       0.00      0.00      0.00       236
          5       0.17      1.00      0.29        66
          6       0.00      0.00      0.00        40

avg / total       0.58      0.50      0.48      1625